{
  "cells": [
    {
      "metadata": {
        "_uuid": "b4578d48b219735043a4d2102119fb307d2fc83f"
      },
      "cell_type": "markdown",
      "source": "\n**A deep neural network model to predict New York city taxi fare price**\n\n"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Initial Python environment setup...\nimport numpy as np # linear algebra\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport keras \nimport matplotlib.pyplot as plt \nimport tensorflow\nfrom tensorflow import keras \nfrom keras.layers import Dense, Activation\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import RMSprop, Adagrad\nimport seaborn as sns\nimport os # reading the input files we have access to\nprint(os.listdir('../input'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb969a26e52931bcaced3cbb7a36d8d8b1b04556"
      },
      "cell_type": "markdown",
      "source": "Section I - Importing the data into the environment. \n\nThe training data set contains 55M rows, while the test data contains 10K rows. When  importing such large volume of the data, the kernel crashes. So the model presented herein is trained only  20M rows. It is assumed that this random sample of 20M rows is representative of entire populaion. It would not be wrong to assume that the accuracy of the model can be further improved upon utilization of the all the avaiable data set for training the model. "
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train=pd.read_csv('../input/train.csv', nrows = 10_000_000)\ntest=pd.read_csv('../input/test.csv')\ntrain.dtypes #checking the data types present",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b1dbc7610bd467f1dfaf9042b5ec638eb2014aaf"
      },
      "cell_type": "markdown",
      "source": "Section II - Processing the data\nAny data set might contain missing values and those should be identified.  "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e808c7e75338b45ca30f9f261dfbc90845700624"
      },
      "cell_type": "code",
      "source": "#Check for any missing values and drop if any \nprint(train.isnull().sum())\ntrain= train.dropna(how = 'any', axis = 'rows')\n\n#check for any outliers in the data by generating descriptive statistics such as mean, maximum, etc. \ntrain.describe()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "97d0aa1deab1c6cf0c97a4a3a12ba7007aada6c5"
      },
      "cell_type": "code",
      "source": "#The maximum passenger count is 208, which practical doesnt make senses. Maximum carrying capacity \n#of passenger can be 10 and minimum capacity can be 1. \n#Eliminate all points above 10 and less than one. \n\n#Fare amount is less than zero. Such outliers are to be eliminated. Few kernels have eliminted high fares. \n#It is possible to have such high values in case of large waiting timings, epensive cars. \n#Only consider lower limit while filtering the fare amount. \n\ntrain=train[train['fare_amount'].between(left=0,right=250)]\ntrain.describe()\ntrain=train[train['passenger_count'].between(left=1,right=7)]\ntrain.describe()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b943cb019a06078cd895a17ccc23390d2f4ea34",
        "scrolled": false
      },
      "cell_type": "markdown",
      "source": "Distance traveled in a ride should always be greater than zero. Eliminate all such points."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "478913581a43becf6478847d79777c71704b8b07",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# Absolute difference in latitude and longitude\ntrain['abs_lat_diff'] = (train['dropoff_latitude'] - train['pickup_latitude']).abs()\ntrain['abs_lon_diff'] = (train['dropoff_longitude'] - train['pickup_longitude']).abs()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "74d20814d9b17fd3af1160d4ca8c514750566608"
      },
      "cell_type": "code",
      "source": "print('Old size: %d' % len(train))\ntrain=train[(train[\"abs_lat_diff\"]>0 )& (train[\"abs_lon_diff\"]>0)]\ntrain=train[(train[\"abs_lat_diff\"]<5 )& (train[\"abs_lon_diff\"]<5)]\nprint('New size: %d' % len(train))\n                    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb3651d8cf8eba26aa4d7866b1ab0b7cea7f267c"
      },
      "cell_type": "markdown",
      "source": "The plot above suggest that there might be few rides where pickup and drop off location are same. Eliminate them"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0108965dce8926882b29bebc205a3fff0b5d657"
      },
      "cell_type": "markdown",
      "source": "Feature extraction\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a82edd3a913167d600451d7723fb8505a9e5a63e"
      },
      "cell_type": "code",
      "source": "R = 6378\n\ndef haversine_np(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n\n    All args must be of equal length.    \n    \n    source: https://stackoverflow.com/a/29546836\n\n    \"\"\"\n    # Convert latitude and longitude to radians\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    # Find the differences\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    # Apply the formula \n    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n    # Calculate the angle (in radians)\n    c = 2 * np.arcsin(np.sqrt(a))\n    # Convert to kilometers\n    km = R * c\n    \n    return km\n\ntrain.head(6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "495ad8a81cf76024527d6e387f3e55de414b5ccf"
      },
      "cell_type": "code",
      "source": "train['haversine'] =  haversine_np(train['pickup_longitude'], train['pickup_latitude'],\n                         train['dropoff_longitude'], train['dropoff_latitude']) \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29a594e30d337a537839174dd7fa166540060634"
      },
      "cell_type": "code",
      "source": "train.head(6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b27d53bc7a3643f37c5d7f9c240dac0762ff19d2"
      },
      "cell_type": "code",
      "source": "#train=train.drop(\"abs_lat_diff\",1)\n#train=train.drop(\"abs_lon_diff\",1)\n#train.head(6)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e007363ab5b6d9881994904f5b2aa12e641e9b2b"
      },
      "cell_type": "code",
      "source": "\n\n\ndef add_time_features(df):\n    df['pickup_datetime'] =  pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')\n    df['year'] = df['pickup_datetime'].apply(lambda x: x.year)\n    df['month'] = df['pickup_datetime'].apply(lambda x: x.month)\n    df['day'] = df['pickup_datetime'].apply(lambda x: x.day)\n    df['hour'] = df['pickup_datetime'].apply(lambda x: x.hour)\n    df['weekday'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n    df['pickup_datetime'] =  df['pickup_datetime'].apply(lambda x: str(x))\n    # Drop 'pickup_datetime' as we won't need it anymore\n    df = df.drop('pickup_datetime', axis=1)\n    \n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c42a34ae65ac3e3970c62bb14fa36ca967a1ccf5",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "\nadd_time_features(train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53f45eb5eb9a8e63b668c750e261bc6a19d33762"
      },
      "cell_type": "code",
      "source": "#Drop the key column\ntrain=train.iloc[0:,1:16]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "860298b79d126f030202745039299f7c4a51002d"
      },
      "cell_type": "code",
      "source": "train.head(6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "152a562f9a645c7c323fd67a975523cce063163f"
      },
      "cell_type": "code",
      "source": "plt.scatter(train[\"weekday\"], train[\"fare_amount\"])\n\n#def activity(row):\n    #if ((row[\"hour\"]<=6) | (row[\"hour\"]>=22)):\n        #return 1\n    #if ((row[\"hour\"]>=6) & (row[\"hour\"]<=10)):\n        #return 2\n    #if ((row[\"hour\"]>=11) & (row[\"hour\"]<=14)):\n        #return 3\n    #if ((row[\"hour\"]>=17) & (row[\"hour\"]<22)):\n        #return 3\n    \n#train['activity'] = train.apply (lambda x: activity(x), axis=1)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1dc2e05c8fc2289899e2d033ba08ffed8e52697d"
      },
      "cell_type": "code",
      "source": "\n\n#correlations=train.corr()\ncorrelations =train.corr()\nfig=plt.figure(figsize=(16,16))\nsns.heatmap(correlations, annot=True, fmt=\".1f\")\nplt.show()\n\nX_train=train.iloc[0:,7:16]\nY_train=train.iloc[0:,0]\nY_train.head(6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c55c8cad24888bd102eac3c38dd86a56b56ef418"
      },
      "cell_type": "code",
      "source": "X_train.head(6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c9ae62ce0502b01b3a40ba654cf8bd7e41eddde"
      },
      "cell_type": "code",
      "source": "random_seed = 10\nfrom tensorflow import keras\nfrom keras.layers import Dense, Activation\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import RMSprop, SGD\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "5627c0a20ffa75cfa14d6cc4e073006826a99e7e"
      },
      "cell_type": "code",
      "source": "from keras import Sequential\nfrom keras.layers import BatchNormalization, Dropout\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=8, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation=\"relu\"))\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11c83b7454fccad2d644959c2e473b44e214e566"
      },
      "cell_type": "code",
      "source": "model.compile(optimizer = 'nadam' , loss = \"mean_squared_error\", metrics=[\"accuracy\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7587e954601c7ad7756c1dd31d4c9ddc6e6c4383",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "model.fit(X_train, Y_train, epochs=4, batch_size=512, validation_data=(X_val,Y_val))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "466f4e5ac3e50cc12a586f60808ad1bdcddfa682"
      },
      "cell_type": "code",
      "source": "test=test=pd.read_csv('../input/test.csv')\ntest.head(6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91f51945518eb9116ead89ab558807dcf8cf1247"
      },
      "cell_type": "code",
      "source": "test['abs_lat_diff'] = (train['dropoff_latitude'] - train['pickup_latitude']).abs()\ntest['abs_lon_diff'] = (train['dropoff_longitude'] - train['pickup_longitude']).abs()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "77b7a4f7957cd1f36e802e8b03e1435e2e548a37"
      },
      "cell_type": "code",
      "source": "test['haversine'] =  haversine_np(test['pickup_longitude'], test['pickup_latitude'],\n                         test['dropoff_longitude'], test['dropoff_latitude']) \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "0435d0a35a1dd719c2dc2a8f3d30f6bc0f90b0a7"
      },
      "cell_type": "code",
      "source": "add_time_features(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6affc9ba46fb4a2a9eb645ddb7f8b7dfaa17db6"
      },
      "cell_type": "code",
      "source": "\ntest.head(6)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9688172d4714f3544dd0b0ae57856922c4754cba"
      },
      "cell_type": "code",
      "source": "test=test.iloc[0:,7:16]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e264791b8c599ff1722b8ce45a876c844caf01c"
      },
      "cell_type": "code",
      "source": "test.head(6)\ntest.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf11c9f544fba35d5093ddb6dfb7cca0022640dc"
      },
      "cell_type": "code",
      "source": "Submissions=model.predict(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74e354cc68ef8904e7798204547a12c4fa61786b"
      },
      "cell_type": "code",
      "source": "submission=pd.read_csv('../input/sample_submission.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60b0f9f1a21588065d16e6da9f0ebddf9201fc6a"
      },
      "cell_type": "code",
      "source": "submission['fare_amount']=Submissions",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd4137f043d929085e4e1efe3209ed34d72e815a"
      },
      "cell_type": "code",
      "source": "submission.to_csv('submission_3.csv',index=False)\nsubmission.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8221ba9c4c4ac11499d7bf5156d86d8edcaaa2d7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}